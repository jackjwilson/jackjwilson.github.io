---
layout: post
title: Paths
---

This blog is based on an abstract I submitted to a conference. 

Gesture is increasingly becoming an accpected part of human meaning making. With a shift towards gesture (an non-linguistic meaning making more generally) there has been an increased focus on iconicity both in and outside of linguistic systems. Within the cognitive semiotic literature on the evolution of communicative systems, there has been a general idea that communication systems shift from being iconic to symbolic. This idea is in line with 'gesture-first' theories of language evolution and has been demonstrated empirically within experimental studies exploring the emergence of systematicity in communication systems. There is also a growing interest in iconic features inherent in both signed languages and ideophones found in many of the world's languages. However, there has been less focus on what iconicity actually is. To use the Peircean conception iconicity, an iconic sign is conected to its referent because there is a perceptual similarity between sign and referent. In this paper I argue that there are at least two distinct types of iconicity and that they lead to distinct hypotheses about how they function, how they evolve and how they might be intergrated within a complex communicational system. 

The first type of iconicity, which might be called *feature iconicity* (FI), involves a sign that picks out features of a referent by possessing features that are perceptually similar to the referent. This type of iconicity is not limited to a single semiotic resource, but can occur in multiple media. For example, a pantomimic gesture depicting a slap is iconic because the behaviour depicted looks like the behaviour referred to. Acoustically, onomatopia is iconic because the sign sounds like its referent. FI is iconic because the features represented as part of a sign bare a perceptual similarity to the referent. However, as argued by Eco, FI is also idealised since the features represented do not usually exhaust the features of the referent. Further, it seems as though FI is typically produced in the same medium as the referent (e.g., visual or acoustic). One potentially exception are the signs "kiki" and "Bouba" of field linguistic fame. In a similar way to the differences in onomatpeic words around the world, FI elements found in sign languages do not necessarily represent the same features. For example, the ASL and BSL signs for CAT both have iconic elements, but they represent different features of the referent (the ears and whiskers, respectively). This suggests that there is potential for great variability in the number of FI signs that we may find in the world's languages. It also suggests a clear path to systematisation and conventionalisation, where iconic features are systematised resulting in increasingly schematic representations, leading to signs that are no longer clearly iconic. 

The second form of iconicity which has received less attention is what might be termed *domain iconicity* (DI). In DI, a sign is related to other elements in a domain and the whole domain is iconically related to another domain. For example, the domain of pitch (ranging from low to high) might be mapped onto the domain of grayscale (ranging from black to white). In this sense, it is the domain that is iconic but that domain is only indexed by the sign. In other words, a sign is not directly iconic but only once the domain indexed is realised. One of the critical features DI is that it is not confined to a single medium. For example, sound is mapped onto vision when pitch is mapped onto grayscale. I will argue that DI is a widespread feature in all communication systems. I will also argue that it is less susceptable to conventionalistation at the level of the individual sign.

Many gestures do not communicate by depicting features of referents but instead communicate by selecting regions in gesture space. Furthermore, it is also possible for gestures to depict dynamic paths from one location in gesture space to another. For such gestures, often referred to as tracing gestures, it is not the hand at any point that is meaningful but the movement (and the trace it leaves behind) that conveys a meaning. The gesture depicts a path. Once conceptualised in this way, it is possible to draw a parallel between tracing gestures and DI. While grayscale or pitch exist in one-dimensional domains, tracing gestures can potential enlist four-dimensions meaningfully (three spatial, and time). This parallel allows for the formalisation of DI that can be applied to multiple domains.     

Following Gardenfors (2014), a path can be represented as a continuous function *p* from the real interval [0,1] to within some space *S*. The starting point for any path is denoted as *p*(0), the endpoint as *p*(1), and for any *i* MEMBER OF (0,1),  *p*(i) is an intermediate point. So a path can be defined as follows

 
1. {p: p(0) < p(1), *i* MEMBER OF (0, 1), p(i) > p(0) AND p(i) < p(1)}  


The points represented can be taken from multi-dimensional spaces. This representation of a path makes it fairly straightforward to map any inheretly sequential domain onto another. One condition is that if a domain has a single dimension then only a single dimension can be mapped onto it (even if the source domain is multi-dimensional). So, pitch and grayscale can be represented as:     

2. {PITCH: p(20 Hz) < p(20,000 Hz), i Hz MEMBER OF (20 Hz, 20,000 Hz), p(i Hz) > p(20 Hz) AND p(i Hz) < p(20,000 Hz)}  
3. {GRAYSCALE: p(black) < p(white), gray MEMBER OF (white, black), p(gray) > p(black) AND p(gray) < p(white)}  

From this, any {PITCH: i Hz} can be mapped onto any {GRAYSCALE: gray} so long as the inherent sequentiality is maintained. That is, if {PITCH: i Hz} --> {GRAYSCALE: gray} there can be no other {PITCH: y Hz} --> {GRAYSCALE: gray y} where {PITCH: y Hz} < {PITCH: i Hz} and {GRAYSCALE: gray y} < {GRAYSCALE: gray}.




 
